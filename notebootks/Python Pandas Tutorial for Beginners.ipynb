{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python Pandas Tutorial for Beginners**\n",
    "\n",
    "Pandas, both the [cuddly animals](../images/baby_pandas.jpg) and the [Python library](https://pandas.pydata.org/), are known for their efficiency – while one munches through bamboo, the other helps you munch through data. Pandas in Python is an amazing data analysis and manipulation tool offering powerful data structures and functions that make handling data a breeze. With Pandas by your side, your data will be as organized as a panda's daily schedule of eating and napping!\n",
    "\n",
    "<div align=\"left\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/e/ed/Pandas_logo.svg\" alt=\"pandas logo\" width=\"40%\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas in Python?\n",
    "\n",
    "Pandas (derived from **pan**el **da**ta) is a powerful Python library for data manipulation and analysis, providing easy-to-use data structures that efficiently handle structured data. Some of its main features include:\n",
    "\n",
    "- **DataFrame and Series**. Pandas uses the concept of Series (1D) and DataFrame (2D) for its data structures, which make data manipulation and analysis straightforward and intuitive.\n",
    "- **Data alignment**. Automatically aligns data across different indexes when performing operations, ensuring consistent and accurate results.\n",
    "-- **Data cleaning**. Pandas provides the tools to handle missing data and duplicates and solve other common issues, so you can be sure you’ll never work with messy datasets.\n",
    "- **Group By functionality**. Enables powerful data aggregation and transformation by grouping data based on specific criteria.\n",
    "- **Integration with other libraries**. Pandas seamlessly integrates with other popular libraries, such as [NumPy](https://numpy.org/) or [Matplotlib](https://matplotlib.org/), allowing enhanced numerical computations and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Python Pandas used for?\n",
    "\n",
    "Ask any data scientist about what they use for data analysis and manipulation, and many of them will recommend or have at least heard of Pandas. It’s a powerful industry-standard tool that’s used for various cases:\n",
    "\n",
    "- **Cleaning and preparing data**. Pandas is extensively used to clean, transform, and prepare data for analysis. You can handle missing data, filter by rows or columns, merge multiple datasets, or apply functions to manipulate data into usable formats.\n",
    "- **Data analysis**. Pandas allow you to calculate statistics, aggregate data, and perform operations like grouping and pivoting, which are essential for summarizing and understanding large datasets. It helps quickly generate data insights, such as finding trends, correlations, or outliers.\n",
    "- **Data aggregation**. Pandas is used to group and aggregate data to summarize information based on specific criteria. This is useful for analyzing patterns over time, such as summarizing sales data by month, calculating the average value of transactions per customer, or aggregating data to find total counts or sums within specific categories.\n",
    "\n",
    "Pandas is widely used across various industries worldwide, including finance, healthcare, eCommerce, logistics, marketing, and more. It plays a crucial role in analyzing diverse datasets, such as stock prices, patient records, purchasing patterns, shipment details, and advertising performance, making it a versatile tool regardless of your field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to install Pandas in Python\n",
    "\n",
    "Without further ado, let’s get started with Pandas and see its powerful capabilities ourselves. First, you’ll need to make sure you’ve got [Python](https://www.python.org/downloads/) installed on your computer. Next, you’ll want to install the Pandas library using one of the methods below.\n",
    "\n",
    "### Installing Pandas with pip\n",
    "\n",
    "The [pip package installer](https://pypi.org/project/pip/) is the simplest way to install Python packages. You can use it to install Pandas by simply running the following command in your terminal tool:\n",
    "\n",
    "```sh\n",
    "pip install pandas\n",
    "```\n",
    "\n",
    "After a short delay, Pandas will be installed on your machine.\n",
    "\n",
    "### Installing Pandas with Anaconda\n",
    "\n",
    "If you aren’t familiar with Python, the easiest way to install Pandas and other useful data analytics packages is with [Anaconda](https://docs.continuum.io/anaconda/install/). It comes preinstalled with all the libraries you need, including Pandas.\n",
    "\n",
    "For more experienced developers, it’s recommended to download [Miniconda](https://docs.anaconda.com/miniconda/miniconda-install/). It allows you to create a minimal, self-contained Python installation that isn’t as big as Anaconda. After you download it, you can then use the package manager to install only the packages you need:\n",
    "\n",
    "```sh\n",
    "conda install -c conda-forge python pandas\n",
    "```\n",
    "\n",
    "### Running a virtual environment\n",
    "\n",
    "Running Pandas in a virtual environment is recommended. You can use the default [venv](https://docs.python.org/3/library/venv.html) module included with Python 3.3 and later. Activate it by running the following command:\n",
    "\n",
    "```sh\n",
    "python3 -m venv name_of_your_env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data in Python using Pandas\n",
    "\n",
    "First, create a Python script file (.py). You can run this script by navigating to the directory in your terminal tool and running the following command:\n",
    "```sh\n",
    "python your_file.py\n",
    "```\n",
    "\n",
    "To start working with data, you’ll need, well, data. Luckily, Pandas supports many different file formats, and you can easily import any of them using very simple and short commands. If you need an example data file, you can download one at the start of each section.\n",
    "\n",
    "Place the file in the same directory as your Python script file. If the data file is placed elsewhere, enter the full path to the file.\n",
    "\n",
    "### Importing a CSV file\n",
    "\n",
    "[Example CSV file](../data/zoo_animals.csv)\n",
    "\n",
    "You can import a CSV file into Pandas with the following method:\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('zoo_animals.csv')\n",
    "```\n",
    "\n",
    "### Importing a text file\n",
    "\n",
    "[Example text file](../data/zoo_animals.txt)\n",
    "\n",
    "You can import a text file into Pandas with the following method:\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('zoo_animals.txt', delimiter='\\t')\n",
    "```\n",
    "\n",
    "The example text file uses a tab delimiter (**`'\\t'`**), but you can also use comma (**`','`**), space (**`' '`**), semicolon (**`';'`**), and pipe (**`'|'`**) options by setting the delimiter value accordingly.\n",
    "\n",
    "### Importing an Excel file\n",
    "\n",
    "[Example Excel file](../data/zoo_animals.xlsx)\n",
    "\n",
    "You can import an Excel file into Pandas with the following method:\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_excel('zoo_animals.xlsx')\n",
    "```\n",
    "\n",
    "### Importing a JSON file\n",
    "\n",
    "[Example JSON file](../data/zoo_animals.json)\n",
    "\n",
    "You can import a JSON file into Pandas with the following method:\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_json('zoo_animals.json')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing and selecting data with Pandas DataFrame\n",
    "\n",
    "As every anxious developer, you’ll want to check whether the data you imported actually appears. Fear not, as we’ll dive into ways how to check and view data through simple functions.\n",
    "\n",
    "### View all data\n",
    "\n",
    "The most simple method to view the entire table is to simply print the **`df`** element. It will display the table in its entirety:\n",
    "```python\n",
    "print(df)\n",
    "```\n",
    "\n",
    "### Viewing data using .head() and .tail()\n",
    "\n",
    "Two more straightforward methods are the **`.head()`** and **`.tail()`**. As the name suggests, these will show the dataset's first or last 5 rows by default. You can enter a custom number of rows instead, too. For instance, let’s print the first 3 rows of our example file:\n",
    "```python\n",
    "print(df.head(3))\n",
    "```\n",
    "\n",
    "Here’s the printed result:\n",
    "```sh\n",
    "     Animal  Age   Habitat  Weight (kg)\n",
    "0     Panda    5    Forest          100\n",
    "1  Elephant   10  Savannah         5400\n",
    "2   Giraffe    7  Savannah          800\n",
    "```\n",
    "\n",
    "To print the last 3 rows, replace **`.head()`** with **`.tail()`**. You can also enter a different custom value to get more or less results.\n",
    "\n",
    "### Viewing data using .describe()\n",
    "\n",
    "The **`.describe()`** method provides statistics for numerical columns. Using it without any additional parameters provides the number of items, mean value, standard deviation, minimum and maximum values, and percentiles. You can read about its customizability in more depth in the [official documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html).\n",
    "```python\n",
    "print(df.describe())\n",
    "```\n",
    "\n",
    "Result:\n",
    "```sh\n",
    "             Age  Weight (kg)\n",
    "count  10.000000    10.000000\n",
    "mean    6.900000   736.800000\n",
    "std     3.842742  1654.753812\n",
    "min     2.000000     3.000000\n",
    "25%     4.250000    88.750000\n",
    "50%     6.500000   175.000000\n",
    "75%     8.750000   340.000000\n",
    "max    15.000000  5400.000000\n",
    "```\n",
    "\n",
    "### Viewing data using .info()\n",
    "\n",
    "Pandas's **`.info()`** method concisely summarizes a DataFrame, giving you an overview of its structure and contents. It’s particularly useful for understanding the types of data within your DataFrame and checking for missing values.\n",
    "```python\n",
    "print(df.info())\n",
    "```\n",
    "\n",
    "Here’s an example result of what it can provide:\n",
    "```sh\n",
    "<class 'pandas.core.frame.DataFrame'>\n",
    "RangeIndex: 10 entries, 0 to 9\n",
    "Data columns (total 4 columns):\n",
    " #   Column       Non-Null Count  Dtype\n",
    "---  ------       --------------  -----\n",
    " 0   Animal       10 non-null     object\n",
    " 1   Age          10 non-null     int64\n",
    " 2   Habitat      10 non-null     object\n",
    " 3   Weight (kg)  10 non-null     int64\n",
    "dtypes: int64(2), object(2)\n",
    "memory usage: 452.0+ bytes\n",
    "```\n",
    "\n",
    "- **RangeIndex** shows the range of the index, indicating how many rows the DataFrame has;\n",
    "- The table shows column names, amount of non-null values in a column, and the data type of the column;\n",
    "- **Memory usage** provides information on the memory usage of the DataFrame, which is useful for large datasets.\n",
    "\n",
    "### Viewing columns using .columns\n",
    "\n",
    "The **`.columns`** attribute in Pandas is used to access the column labels of a DataFrame. It returns the names of all the columns in the DataFrame.\n",
    "```python\n",
    "print(df.columns)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```sh\n",
    "Index(['Animal', 'Age', 'Habitat', 'Weight (kg)'], dtype='object')\n",
    "```\n",
    "\n",
    "You can also use this method to perform all sorts of operations on the columns. For example, you can check if the column exists:\n",
    "```python\n",
    "if 'Age' in df.columns:\n",
    "    print(\"The 'Age' column exists.\")\n",
    "```\n",
    "\n",
    "### Selecting rows using .loc[] and .iloc[]\n",
    "\n",
    "**`.loc[]`** and **`.iloc[]`** are used to select rows and columns from a DataFrame to view or edit row data. They both perform a similar job, but the approach to how they select data is slightly different. Let’s see how.\n",
    "\n",
    "Using **`.loc[]`** (label-based indexing), you can select data by label or a boolean array. In our example file, let’s use it to find all rows that contain animals whose habitats are 'Savannah':\n",
    "```python\n",
    "giraffe_row = df.loc[df['Habitat'] == 'Savannah']\n",
    "print(giraffe_row)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```sh\n",
    "     Animal  Age   Habitat  Weight (kg)\n",
    "1  Elephant   10  Savannah         5400\n",
    "2   Giraffe    7  Savannah          800\n",
    "3      Lion    4  Savannah          190\n",
    "```\n",
    "\n",
    "Using **`.iloc[]`** (integer-based indexing), you can select data by position – simply enter the number of the row you want to find. Remember the [zero-based numbering](https://en.wikipedia.org/wiki/Zero-based_numbering) in Python, so the row you want to find will always be +1 higher. Here’s how you’d print the third row of your dataset:\n",
    "```python\n",
    "third_row = df.iloc[2]\n",
    "print(third_row)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```sh\n",
    "Animal          Giraffe\n",
    "Age                   7\n",
    "Habitat        Savannah\n",
    "Weight (kg)         800\n",
    "Name: 2, dtype: object\n",
    "```\n",
    "\n",
    "### Selecting columns\n",
    "\n",
    "The process of selecting columns is very similar to the above, with slightly different syntax. To select a specific column, use the .loc[] method with a colon as the first indexer. This signifies that the first indexer should select all rows and the second only the 'Animal' column:\n",
    "```python\n",
    "animal_column = df.loc[:, 'Animal']\n",
    "print(animal_column)\n",
    "```\n",
    "\n",
    "Output:\n",
    "```sh\n",
    "0       Panda\n",
    "1    Elephant\n",
    "2     Giraffe\n",
    "3        Lion\n",
    "4       Zebra\n",
    "5    Kangaroo\n",
    "6     Penguin\n",
    "7       Tiger\n",
    "8     Gorilla\n",
    "9    Flamingo\n",
    "Name: Animal, dtype: object\n",
    "```\n",
    "\n",
    "The **`.iloc[]`** variant is pretty much the same, but instead of entering a specific name, simply enter the numerical index value of a column:\n",
    "```python\n",
    "df.iloc[:, 2]  # Selects all rows and column 3\n",
    "```\n",
    "\n",
    "The methods provided are just simple examples of what Pandas can do with just a few lines of code. [Read here](https://pandas.pydata.org/docs/user_guide/indexing.html) if you’re interested in more specific ways of indexing and selecting data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying row data with `.loc[]` and `.iloc[]`\n",
    "\n",
    "Now that you’ve learned how to find what you need in a dataset let’s learn ways to modify it. It’s really quite simple – you just need to use the same **`.loc[]`** and **`.iloc[]`** methods and assign a new value to the extracted row.\n",
    "\n",
    "Let’s say you want to change the weight value for the '*Penguin*' row because it ate too much fish and gained weight. To do that, use the **`.loc[]`** method to match the '*Animal*' column to the '*Penguin*' row and set the '*Weight*' column to a new value:\n",
    "```python\n",
    " df.loc[df['Animal'] == 'Penguin', 'Weight (kg)'] = 40\n",
    "```\n",
    "\n",
    "You can perform a similar operation with **`.iloc[]`** by specifying the row and column you want to edit:\n",
    "```python\n",
    "df.iloc[6, 3] = 40 # 7th row, 4th column\n",
    "```\n",
    "\n",
    "Once you’re finished, remember that all the changes aren’t made directly to the imported file but stored in memory. To print the result, you’ll need to use the **`.to_csv()`** or an equivalent file method:\n",
    "```python\n",
    "df.to_csv('zoo_animals.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying columns with DataFrame\n",
    "\n",
    "Knowing how to change values inside your data is useful, but what if you’re not happy with the structure? Great news because Pandas allows you to perform data manipulation and modify how it appears. Let’s take a look at a few ways how you can play around with columns.\n",
    "\n",
    "### Adding a column\n",
    "\n",
    "You can add a column by assigning a new value or a series of values to a new column name. There are several ways to do it, but here are a few main methods with examples:\n",
    "- **Add a column with a constant value**. Create a column and set all its values to the same;\n",
    "```python\n",
    "    df['Endangered'] = 'Yes'\n",
    "```\n",
    "- **Add a column based on existing columns**. Add a new column that is the sum of another two columns;\n",
    "```python\n",
    "    df['Age_Weight_Sum'] = df['Age'] + df['Weight (kg)']\n",
    "```\n",
    "- **`Add a column with conditional values`**. Mark animals as 'Heavy' if their weight is over 300 kg.\n",
    "```python\n",
    "    df['Weight_Category'] = df['Weight (kg)'].apply(lambda x: 'Heavy' if x > 300 else 'Light')\n",
    "```\n",
    "\n",
    "### Dropping a column\n",
    "\n",
    "If you find that a column is no longer useful, you can **`.drop()`** it in the trash. Or toss it gently on the floor, whatever your definition of drop is. Either way, it’s going to disappear off the table.\n",
    "\n",
    "To drop a single column, enter the following:\n",
    "```python\n",
    "df = df.drop('Weight (kg)', axis=1)\n",
    "```\n",
    "\n",
    "If you want to drop multiple columns, you’ll have to specify each of their names:\n",
    "```python\n",
    "df = df.drop(['Age', 'Habitat'], axis=1)\n",
    "```\n",
    "\n",
    "If you’re not sure what **`axis=1`** stands for, it simply tells Pandas to drop a column. If you wanted to drop a row, you’d write the row name with **`axis=0`** instead. This little detail is useful when both column and row value names match, and you need to be specific about which one to drop.\n",
    "\n",
    "### Renaming a column\n",
    "\n",
    "Renaming columns in Pandas can be done using the **`.rename()`** method or by directly modifying the columns attribute. Here’s how you can do it:\n",
    "```python\n",
    "df = df.rename(columns={'Animal': 'Species'})\n",
    "```\n",
    "\n",
    "### Filtering by column\n",
    "\n",
    "Filtering a DataFrame by a column in Pandas involves selecting rows that meet certain conditions based on the values in a specific column. Here are a few scenarios:\n",
    "\n",
    "Filter rows where the habitat is '*Savannah*':\n",
    "```python\n",
    "filtered_df = df[df['Habitat'] == 'Savannah']\n",
    "```\n",
    "\n",
    "Filter rows where the '*Age*' column is more than 5:\n",
    "```python\n",
    "filtered_df = df[df['Age'] > 5]\n",
    "```\n",
    "\n",
    "Filter rows where the '*Animal*' is either '*Panda*' or '*Lion*':\n",
    "```python\n",
    "filtered_df = df[df['Animal'].isin(['Panda', 'Lion'])]\n",
    "```\n",
    "\n",
    "### Sorting by column names\n",
    "\n",
    "You can use the **`.sort_values()`** method to sort your DataFrame by one or more columns. Here’s how you can sort by the '*Weight (kg)*' column in descending order:\n",
    "```python\n",
    "df_sorted = df.sort_values(by='Weight (kg)', ascending=False)\n",
    "```\n",
    "\n",
    "By default, Pandas will sort in ascending order, so you don’t need to write an additional parameter if you want to do so instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping data with the .groupby() function\n",
    "\n",
    "The **`.groupby()`** function in Pandas is used to group data based on one or more columns and then perform aggregate operations on those groups. It’s useful for summarizing and analyzing data by categories.\n",
    "\n",
    "The function primarily splits data into groups based on the values of the specified columns. It then applies an aggregation and combines the result as a new DataFrame. Here are a few of the more common aggregations that can be performed:\n",
    "\n",
    "- **`.mean()`**. Computes the mean of each group;\n",
    "- **`.sum()`**. Computes the sum of each group;\n",
    "- **`.count()`**. Counts the number of non-null values in each group;\n",
    "- **`.min() / .max()`**. Computes the minimum or maximum value in each group.\n",
    "\n",
    "### Grouping data by a single column\n",
    "\n",
    "To group data by a single column, you must pick a column and pair it with an aggregation function. A single column might not provide enough data needed for sensible results, so it’s recommended to always group by at least 2 columns. Here’s a way to group by a single column:\n",
    "```python\n",
    "grouped_count = df.groupby('Habitat').count()\n",
    "```\n",
    "\n",
    "The numbers tell you how many rows of data exist for each habitat in your DataFrame. While not entirely useful, it can be a good way to check if any of the rows are missing data.\n",
    "\n",
    "### Grouping data by multiple columns\n",
    "\n",
    "Do you want to know which habitat has the heaviest animals? If you promise not to use this data for fat-shaming them, here’s the secret formula for how to do that:\n",
    "```python\n",
    "grouped_avg_weight = df.groupby('Habitat')['Weight (kg)'].mean()\n",
    "```\n",
    "\n",
    "The function here groups all the animals by habitat and weight. It then takes the mean value of each habitat, providing you with a list of habitats and the average animal weight for each:\n",
    "```sh\n",
    "Habitat\n",
    "Antarctica      50.0\n",
    "Forest         100.0\n",
    "Grassland      232.5\n",
    "Jungle         190.0\n",
    "Savannah      2130.0\n",
    "Wetlands         3.0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging, joining, and concatenating DataFrames\n",
    "\n",
    "In a real-world scenario, all the data you need won’t be constricted to just a single DataFrame. It’s actually a good practice to separate your data into different tables and use methods to join them when retrieving results. For example, a zoo might have several data tables – on top of the existing list, each animal could also have a separate table about their diet and conservation status:\n",
    "```sh\n",
    "     Animal       Diet Conservation Status\n",
    "0     Panda  Herbivore          Vulnerable\n",
    "1  Elephant  Herbivore          Endangered\n",
    "2   Giraffe  Herbivore          Vulnerable\n",
    "3      Lion  Carnivore          Vulnerable\n",
    "4     Zebra  Herbivore       Least Concern\n",
    "```\n",
    "\n",
    "You can grab the example [CSV file here](../data/animal_info.csv) or create your own.\n",
    "\n",
    "Import the file the same way as you did previously. Here’s the modified beginning of the code:\n",
    "```python\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('zoo_animals.csv')\n",
    "df2 = pd.read_csv('animal_info.csv')\n",
    "```\n",
    "\n",
    "The main difference to note is that the *df* variables were numbered, and a second DataFrame was imported.\n",
    "\n",
    "### Merging DataFrames\n",
    "\n",
    "Merging is a method to combine two DataFrames based on one or more keys (columns). If you’ve worked with [SQL](https://en.wikipedia.org/wiki/Microsoft_SQL_Server) before, you’ll find these join methods very familiar (inner, outer, left, and right joins).\n",
    "\n",
    "To merge rows, write the following code:\n",
    "```python\n",
    "pd.merge(df1, df2, how='inner', on='Animal')\n",
    "```\n",
    "\n",
    "The above will use the *inner* [join method](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.join.html) and merge on the shared column '*Animal*.' Here’s the full code to help visualize the process:\n",
    "```python\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('zoo_animals.csv')\n",
    "df2 = pd.read_csv('animal_info.csv')\n",
    "\n",
    "new_table = pd.merge(df1, df2, how='inner', on='Animal')\n",
    "\n",
    "print(new_table)\n",
    "```\n",
    "\n",
    "### Joining DataFrames\n",
    "\n",
    "The join method is used to combine two DataFrames based on their indexes or a key column. It's a convenient method for merging with an index, which is useful when the DataFrames share the same index:\n",
    "```python\n",
    "df1.join(df2, how='join_type', on='key_column')\n",
    "```\n",
    "\n",
    "### Concatenating multiple DataFrames\n",
    "\n",
    "Concatenation is used to append DataFrames either vertically (stacked rows) or horizontally (added columns). It's useful when you have DataFrames with the same structure or when you want to stack them. The syntax is as follows:\n",
    "```python\n",
    "pd.concat([df1, df2], axis=0)  # axis=0 for row-wise (vertical) concatenation\n",
    "pd.concat([df1, df2], axis=1)  # axis=1 for column-wise (horizontal) \n",
    "```\n",
    "\n",
    "For more in-depth information, check the official documentation on how to [merge, join, concatenate, and compare](https://pandas.pydata.org/docs/user_guide/merging.html) DataFrames.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data visualization with Pandas\n",
    "\n",
    "While presenting data in a terminal can make you look cool and feel like a hacker, it won’t hold the attention of our current age generation. The solution? Present it in a nice-looking visual!\n",
    "\n",
    "Here’s the good and bad news. The bad news is that Pandas, on its own, doesn’t have any ways to visualize data. The good news is that it integrates wonderfully with libraries that can, such as [Matplotlib](https://matplotlib.org/).\n",
    "\n",
    "To begin, make sure you have a plotting library installed:\n",
    "```sh\n",
    "pip install matplotlib\n",
    "```\n",
    "\n",
    "Then, include it in your code:\n",
    "```python\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "You can plot data directly from a DataFrame using the **`.plot`** function. Different ways exist, so pick one that you find best suited for your data.\n",
    "\n",
    "As an example, a bar plot is used to compare quantities of categorical data. The entire script looks like this:\n",
    "```python\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df= pd.read_csv('zoo_animals.csv')\n",
    "\n",
    "df.groupby('Habitat')['Weight (kg)'].mean().plot(kind='bar')\n",
    "plt.title('Average Weight by Habitat')\n",
    "plt.ylabel('Weight (kg)')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "Here’s the beautiful result:\n",
    "\n",
    "<img src=\"../images/Average Weight by Habitat 2.png\" alt=\"Average Weight by Habitat\" width=\"60%\"/>\n",
    "\n",
    "Use the buttons below the graph to pan and zoom into the data, as well as configure subplots or save the graph as an image file. It’s an incredibly fast way to visualize data with just a few lines of code!\n",
    "\n",
    "You can even explore different types of graphs, as well as libraries that can help it visualize in more exciting ways. The best part is that Pandas is built to easily integrate with a lot of them, so the possibilities are endless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best practices and tips\n",
    "\n",
    "When working with Pandas, following optimization techniques, best coding practices, and avoiding common pitfalls can greatly improve your code's performance and readability.\n",
    "\n",
    "### Optimizing performance with Pandas\n",
    "Performance optimization is a top priority when working with large datasets in Pandas. One way to improve speed is using vectorized operations rather than iterating over rows, as Pandas is built for column-wise operations. Memory usage can be reduced by downcasting data types and filtering data early on using **`.query`** or boolean indexing to avoid unnecessary processing.\n",
    "\n",
    "### Writing clean and efficient Pandas code\n",
    "Writing clean code increases readability and efficiency. Start by keeping your code modular by breaking complex chains of operations into smaller, reusable functions. It’s also important to use clear and descriptive column names so that developers who use your code don’t get lost. Documentation is also key – use comments and write comprehensive guides to explain how your code works (you’ll thank yourself later, too).\n",
    "\n",
    "### Common pitfalls to avoid\n",
    "While Pandas may seem intuitive and simple to use, there are a few things worth keeping in mind that many might overlook:\n",
    "\n",
    "- **Using loops instead of vectorized operations**. Iterating over DataFrame rows with loops is much slower compared to Pandas' built-in vectorized functions. Always prefer vectorized operations for faster performance.\n",
    "- **Neglecting missing data**. Failing to check and handle NaN values before calculations can lead to unexpected results. Use methods like **`.fillna()`** or **`.dropna()`** to manage missing data appropriately.\n",
    "Chained indexing. Avoid using chained indexing, as it can lead to ambiguous behavior and performance issues. Instead, use **`.loc[]`** for reliable and efficient data selection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final words\n",
    "Python Pandas remains one of the most intuitive libraries for data manipulation and analysis. Although it may have a steep learning curve, by progressing step by step, you'll soon be able to master it with confidence. Apply the methods covered in this article, experiment with them, and carry this knowledge forward in your data analytics journey. ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
